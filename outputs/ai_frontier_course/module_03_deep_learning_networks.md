# æ¨¡å—ä¸‰ï¼šæ·±åº¦å­¦ä¹ ä¸ç¥ç»ç½‘ç»œ

## è¯¾ç¨‹ä¿¡æ¯
- **æ¨¡å—ç¼–å·**ï¼šModule 03
- **æ¨¡å—åç§°**ï¼šæ·±åº¦å­¦ä¹ ä¸ç¥ç»ç½‘ç»œ
- **å­¦æ—¶å®‰æ’**ï¼šç†è®ºè¯¾ç¨‹ 10å­¦æ—¶ï¼Œå®è·µè¯¾ç¨‹ 8å­¦æ—¶
- **å­¦ä¹ ç›®æ ‡**ï¼šæŒæ¡æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæŠ€æœ¯ã€ç½‘ç»œæ¶æ„è®¾è®¡å’Œè®­ç»ƒä¼˜åŒ–æ–¹æ³•

## ç¬¬ä¸€ç« ï¼šæ·±åº¦å­¦ä¹ åŸºç¡€ç†è®º

### 1.1 ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ

ğŸ§  **ç®€å•ç†è§£**ï¼šæ·±åº¦å­¦ä¹ å°±æ˜¯è®©è®¡ç®—æœºåƒäººè„‘ä¸€æ ·ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å’Œè¯†åˆ«å¤æ‚çš„æ¨¡å¼ã€‚

**ä¸ºä»€ä¹ˆå«"æ·±åº¦"ï¼Ÿ**
- ğŸ¢ **å¤šå±‚ç»“æ„**ï¼šå°±åƒé«˜æ¥¼å¤§å¦æœ‰å¾ˆå¤šå±‚ï¼Œç¥ç»ç½‘ç»œä¹Ÿæœ‰å¾ˆå¤šå±‚
- ğŸ“š **å±‚å±‚é€’è¿›**ï¼šæ¯ä¸€å±‚éƒ½åœ¨å‰ä¸€å±‚çš„åŸºç¡€ä¸Šå­¦ä¹ æ›´å¤æ‚çš„ç‰¹å¾
- ğŸ¯ **æ·±å…¥ç†è§£**ï¼šèƒ½å¤Ÿç†è§£æ•°æ®ä¸­æ›´æ·±å±‚æ¬¡çš„è§„å¾‹å’Œæ¨¡å¼

**ç”Ÿæ´»ä¸­çš„æ·±åº¦å­¦ä¹ ä¾‹å­**ï¼š
- ğŸ“± **äººè„¸è¯†åˆ«**ï¼šæ‰‹æœºè§£é”æ—¶è¯†åˆ«ä½ çš„è„¸
- ğŸ—£ï¸ **è¯­éŸ³åŠ©æ‰‹**ï¼šSiriã€å°çˆ±åŒå­¦ç†è§£ä½ è¯´çš„è¯
- ğŸš— **è‡ªåŠ¨é©¾é©¶**ï¼šæ±½è½¦è¯†åˆ«çº¢ç»¿ç¯ã€è¡Œäººã€å…¶ä»–è½¦è¾†
- ğŸ¨ **AIç»˜ç”»**ï¼šæ ¹æ®æ–‡å­—æè¿°ç”Ÿæˆå›¾ç‰‡
- ğŸ’¬ **æ™ºèƒ½ç¿»è¯‘**ï¼šå®æ—¶ç¿»è¯‘ä¸åŒè¯­è¨€

### 1.2 æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³

#### æ¨¡ä»¿å¤§è„‘çš„å·¥ä½œæ–¹å¼

ğŸ§  **äººè„‘æ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ**

æƒ³è±¡ä½ ç¬¬ä¸€æ¬¡çœ‹åˆ°ä¸€åªçŒ«ï¼š
1. ğŸ‘ï¸ **çœ¼ç›æ¥æ”¶ä¿¡æ¯**ï¼šçœ‹åˆ°æ¯›èŒ¸èŒ¸çš„ã€å››æ¡è…¿çš„åŠ¨ç‰©
2. ğŸ§  **å¤§è„‘åˆ†å±‚å¤„ç†**ï¼š
   - **ç¬¬ä¸€å±‚**ï¼šè¯†åˆ«è¾¹ç¼˜ã€çº¿æ¡
   - **ç¬¬äºŒå±‚**ï¼šè¯†åˆ«çœ¼ç›ã€è€³æœµã€å°¾å·´ç­‰éƒ¨ä½
   - **ç¬¬ä¸‰å±‚**ï¼šç»„åˆæˆ"çŒ«"çš„æ¦‚å¿µ
3. ğŸ’­ **å½¢æˆè®¤çŸ¥**ï¼š"è¿™æ˜¯ä¸€åªçŒ«"

ğŸ¤– **æ·±åº¦å­¦ä¹ æ¨¡ä»¿è¿™ä¸ªè¿‡ç¨‹**ï¼š

```python
# è¯†åˆ«çŒ«çš„è¿‡ç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
è¾“å…¥å›¾ç‰‡ â†’ ç¬¬1å±‚ï¼ˆè¯†åˆ«è¾¹ç¼˜ï¼‰ â†’ ç¬¬2å±‚ï¼ˆè¯†åˆ«éƒ¨ä½ï¼‰ â†’ ç¬¬3å±‚ï¼ˆè¯†åˆ«æ•´ä½“ï¼‰ â†’ è¾“å‡ºï¼š"è¿™æ˜¯çŒ«"
```

**æ¯ä¸€å±‚çš„ä½œç”¨**ï¼š
- ğŸ” **ç¬¬1å±‚ï¼ˆè¾¹ç¼˜æ£€æµ‹å±‚ï¼‰**ï¼šæ‰¾å‡ºå›¾ç‰‡ä¸­çš„çº¿æ¡ã€è¾¹ç¼˜
- ğŸ¯ **ç¬¬2å±‚ï¼ˆç‰¹å¾ç»„åˆå±‚ï¼‰**ï¼šæŠŠçº¿æ¡ç»„åˆæˆçœ¼ç›ã€è€³æœµç­‰
- ğŸ§© **ç¬¬3å±‚ï¼ˆæ¨¡å¼è¯†åˆ«å±‚ï¼‰**ï¼šæŠŠå„ä¸ªéƒ¨ä½ç»„åˆæˆå®Œæ•´çš„çŒ«
- ğŸ·ï¸ **è¾“å‡ºå±‚**ï¼šç»™å‡ºæœ€ç»ˆç­”æ¡ˆ

#### ä¸ºä»€ä¹ˆéœ€è¦"æ·±åº¦"ï¼Ÿ

**æµ…å±‚ç½‘ç»œ vs æ·±å±‚ç½‘ç»œ**

ğŸ¥ **æµ…å±‚ç½‘ç»œï¼ˆåƒç…é¥¼ï¼‰**ï¼š
- åªæœ‰1-2å±‚
- åªèƒ½å­¦ä¹ ç®€å•çš„æ¨¡å¼
- **ä¾‹å­**ï¼šåªèƒ½è¯†åˆ«"åœ†å½¢"ã€"æ–¹å½¢"

ğŸ—ï¸ **æ·±å±‚ç½‘ç»œï¼ˆåƒæ‘©å¤©å¤§æ¥¼ï¼‰**ï¼š
- æœ‰å¾ˆå¤šå±‚ï¼ˆå‡ åå±‚ç”šè‡³ä¸Šç™¾å±‚ï¼‰
- èƒ½å­¦ä¹ å¤æ‚çš„æ¨¡å¼
- **ä¾‹å­**ï¼šèƒ½è¯†åˆ«"äººè„¸"ã€"æ±½è½¦"ã€"é£æ™¯"

**ç”¨æ­ç§¯æœ¨çš„ä¾‹å­ç†è§£**ï¼š
- ğŸ§± **ç¬¬1å±‚**ï¼šå­¦ä¼šè¯†åˆ«ç§¯æœ¨å—ï¼ˆåŸºæœ¬å½¢çŠ¶ï¼‰
- ğŸ  **ç¬¬2å±‚**ï¼šå­¦ä¼šç”¨ç§¯æœ¨æ­æˆ¿å­ï¼ˆç®€å•ç»“æ„ï¼‰
- ğŸ™ï¸ **ç¬¬3å±‚**ï¼šå­¦ä¼šæ­å»ºåŸå¸‚ï¼ˆå¤æ‚åœºæ™¯ï¼‰

#### æ·±åº¦å­¦ä¹ çš„"å­¦ä¹ "è¿‡ç¨‹

ğŸ“ **å°±åƒå­¦ç”Ÿå­¦ä¹ ä¸€æ ·**ï¼š

1. ğŸ“– **çœ‹ä¾‹å­**ï¼šç»™ç½‘ç»œçœ‹å¤§é‡çš„çŒ«å’Œç‹—çš„ç…§ç‰‡
2. ğŸ¤” **çŒœç­”æ¡ˆ**ï¼šç½‘ç»œå°è¯•åˆ¤æ–­æ¯å¼ ç…§ç‰‡æ˜¯çŒ«è¿˜æ˜¯ç‹—
3. âœ… **æ£€æŸ¥å¯¹é”™**ï¼šå‘Šè¯‰ç½‘ç»œæ­£ç¡®ç­”æ¡ˆ
4. ğŸ”§ **è°ƒæ•´å‚æ•°**ï¼šç½‘ç»œæ ¹æ®é”™è¯¯è°ƒæ•´å†…éƒ¨å‚æ•°
5. ğŸ”„ **é‡å¤ç»ƒä¹ **ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹åƒä¸‡æ¬¡
6. ğŸ¯ **å˜æˆä¸“å®¶**ï¼šæœ€ç»ˆç½‘ç»œèƒ½å‡†ç¡®è¯†åˆ«çŒ«å’Œç‹—

**å…³é”®æ¦‚å¿µ**ï¼š
- ğŸ“Š **è®­ç»ƒæ•°æ®**ï¼šç”¨æ¥æ•™ç½‘ç»œçš„ä¾‹å­ï¼ˆå°±åƒæ•™ç§‘ä¹¦ï¼‰
- âš–ï¸ **å‚æ•°è°ƒæ•´**ï¼šç½‘ç»œå†…éƒ¨çš„"å­¦ä¹ "è¿‡ç¨‹ï¼ˆå°±åƒè®°å¿†çŸ¥è¯†ç‚¹ï¼‰
- ğŸ¯ **é¢„æµ‹**ï¼šå­¦ä¼šåå¯¹æ–°æ•°æ®çš„åˆ¤æ–­ï¼ˆå°±åƒè€ƒè¯•ç­”é¢˜ï¼‰

**ä¼˜åŒ–ç†è®ºåŸºç¡€**

*å‡¸å‡½æ•°ä¸å‡¸ä¼˜åŒ–*
- **å‡¸å‡½æ•°**ï¼šf(Î»x + (1-Î»)y) â‰¤ Î»f(x) + (1-Î»)f(y)
- **å¼ºå‡¸å‡½æ•°**ï¼šå­˜åœ¨Î¼ > 0ä½¿å¾—f(x) - (Î¼/2)||x||Â²ä¸ºå‡¸å‡½æ•°
- **å‡¸ä¼˜åŒ–**ï¼šç›®æ ‡å‡½æ•°å’Œçº¦æŸéƒ½æ˜¯å‡¸çš„ä¼˜åŒ–é—®é¢˜
- **å…¨å±€æœ€ä¼˜æ€§**ï¼šå‡¸ä¼˜åŒ–çš„å±€éƒ¨æœ€ä¼˜å³å…¨å±€æœ€ä¼˜

*éå‡¸ä¼˜åŒ–æŒ‘æˆ˜*
- å¤šä¸ªå±€éƒ¨æœ€ä¼˜ç‚¹
- éç‚¹é—®é¢˜
- æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸
- ä¼˜åŒ–ç®—æ³•çš„æ”¶æ•›æ€§

**æ¦‚ç‡è®ºä¸ä¿¡æ¯è®º**

*æ¦‚ç‡åˆ†å¸ƒ*
- **é«˜æ–¯åˆ†å¸ƒ**ï¼šN(Î¼, ÏƒÂ²)
- **ä¼¯åŠªåˆ©åˆ†å¸ƒ**ï¼šBernoulli(p)
- **å¤šé¡¹åˆ†å¸ƒ**ï¼šMultinomial(n, p)
- **æŒ‡æ•°æ—åˆ†å¸ƒ**ï¼šç»Ÿä¸€çš„å‚æ•°åŒ–å½¢å¼

*ä¿¡æ¯è®ºæ¦‚å¿µ*
- **ç†µ**ï¼šH(X) = -âˆ‘P(x)log P(x)
- **äº¤å‰ç†µ**ï¼šH(P,Q) = -âˆ‘P(x)log Q(x)
- **KLæ•£åº¦**ï¼šD_KL(P||Q) = âˆ‘P(x)log(P(x)/Q(x))
- **äº’ä¿¡æ¯**ï¼šI(X;Y) = H(X) - H(X|Y)

#### çº¿æ€§ä»£æ•°åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨

**çŸ©é˜µè¿ç®—**

*çŸ©é˜µä¹˜æ³•*
- ç¥ç»ç½‘ç»œå‰å‘ä¼ æ’­çš„æ ¸å¿ƒè¿ç®—
- æ‰¹é‡å¤„ç†çš„æ•°å­¦è¡¨ç¤º
- GPUå¹¶è¡Œè®¡ç®—çš„åŸºç¡€

*ç‰¹å¾å€¼åˆ†è§£*
```
A = QÎ›Qâ»Â¹
```
- ç†è§£ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›
- åˆ†ææ¢¯åº¦ä¼ æ’­ç‰¹æ€§
- ç½‘ç»œå‹ç¼©å’ŒåŠ é€Ÿ

*å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰*
```
A = UÎ£Váµ€
```
- çŸ©é˜µçš„ä½ç§©è¿‘ä¼¼
- ä¸»æˆåˆ†åˆ†æçš„åŸºç¡€
- ç½‘ç»œå‚æ•°çš„å‹ç¼©

**å¼ é‡è¿ç®—**

*å¼ é‡åŸºç¡€*
- **æ ‡é‡**ï¼š0é˜¶å¼ é‡
- **å‘é‡**ï¼š1é˜¶å¼ é‡
- **çŸ©é˜µ**ï¼š2é˜¶å¼ é‡
- **é«˜é˜¶å¼ é‡**ï¼šå¤šç»´æ•°ç»„

*å¼ é‡æ“ä½œ*
- **é‡å¡‘ï¼ˆReshapeï¼‰**ï¼šæ”¹å˜å¼ é‡å½¢çŠ¶
- **è½¬ç½®ï¼ˆTransposeï¼‰**ï¼šäº¤æ¢å¼ é‡ç»´åº¦
- **å¹¿æ’­ï¼ˆBroadcastingï¼‰**ï¼šä¸åŒå½¢çŠ¶å¼ é‡çš„è¿ç®—
- **æ”¶ç¼©ï¼ˆContractionï¼‰**ï¼šå¼ é‡ä¹˜æ³•çš„æ³›åŒ–

### 1.2 ç¥ç»ç½‘ç»œçš„é€šç”¨é€¼è¿‘ç†è®º

#### ä¸‡èƒ½é€¼è¿‘å®šç†

**å®šç†é™ˆè¿°**

*Cybenkoå®šç†ï¼ˆ1989ï¼‰*
è®¾Ïƒæ˜¯éå¸¸æ•°ã€æœ‰ç•Œã€å•è°ƒé€’å¢çš„è¿ç»­å‡½æ•°ã€‚åˆ™å¯¹äºä»»æ„è¿ç»­å‡½æ•°fåœ¨ç´§é›†Kä¸Šï¼Œå­˜åœ¨æœ‰é™ä¸ªéšè—å•å…ƒçš„å•éšå±‚å‰é¦ˆç½‘ç»œï¼Œä½¿å¾—ï¼š
```
|F(x) - f(x)| < Îµ, âˆ€x âˆˆ K
```

*Hornikå®šç†ï¼ˆ1991ï¼‰*
å¤šå±‚å‰é¦ˆç½‘ç»œæ˜¯ä¸‡èƒ½é€¼è¿‘å™¨ï¼Œåªè¦æœ‰è¶³å¤Ÿçš„éšè—å•å…ƒã€‚

**ç†è®ºæ„ä¹‰**
- ç¥ç»ç½‘ç»œå…·æœ‰å¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›
- ç†è®ºä¸Šå¯ä»¥é€¼è¿‘ä»»æ„è¿ç»­å‡½æ•°
- ä¸ºæ·±åº¦å­¦ä¹ æä¾›äº†ç†è®ºåŸºç¡€

**å®è·µå±€é™**
- å®šç†ä¸æä¾›ç½‘ç»œç»“æ„çš„æ„é€ æ–¹æ³•
- ä¸ä¿è¯å­¦ä¹ ç®—æ³•èƒ½æ‰¾åˆ°æœ€ä¼˜å‚æ•°
- æ‰€éœ€çš„ç½‘ç»œè§„æ¨¡å¯èƒ½éå¸¸å¤§

#### æ·±åº¦çš„ä¼˜åŠ¿

**è¡¨è¾¾æ•ˆç‡**

*æŒ‡æ•°çº§è¡¨è¾¾èƒ½åŠ›*
- æ·±åº¦ç½‘ç»œå¯ä»¥ç”¨æŒ‡æ•°çº§å°‘çš„å‚æ•°è¡¨è¾¾å¤æ‚å‡½æ•°
- æµ…å±‚ç½‘ç»œå¯èƒ½éœ€è¦æŒ‡æ•°çº§å¤šçš„ç¥ç»å…ƒ
- å±‚æ¬¡åŒ–è¡¨ç¤ºçš„ä¼˜åŠ¿

*ç»„åˆæ€§*
- ä½å±‚å­¦ä¹ ç®€å•ç‰¹å¾
- é«˜å±‚ç»„åˆå¤æ‚æ¦‚å¿µ
- ç¬¦åˆäººç±»è®¤çŸ¥çš„å±‚æ¬¡ç»“æ„

**ä¼˜åŒ–æ™¯è§‚**

*æŸå¤±å‡½æ•°çš„å‡ ä½•ç»“æ„*
- æ·±åº¦ç½‘ç»œçš„æŸå¤±å‡½æ•°æ˜¯é«˜ç»´éå‡¸çš„
- å­˜åœ¨å¤§é‡å±€éƒ¨æœ€ä¼˜å’Œéç‚¹
- æ¢¯åº¦ä¸‹é™å¾€å¾€èƒ½æ‰¾åˆ°å¥½çš„è§£

*éšå¼æ­£åˆ™åŒ–*
- SGDå…·æœ‰éšå¼æ­£åˆ™åŒ–æ•ˆæœ
- æ·±åº¦ç½‘ç»œå€¾å‘äºå­¦ä¹ ç®€å•çš„è§£
- æ³›åŒ–èƒ½åŠ›çš„ç†è®ºè§£é‡Š

### 1.3 åå‘ä¼ æ’­ç®—æ³•è¯¦è§£

#### è®¡ç®—å›¾ä¸è‡ªåŠ¨å¾®åˆ†

**è®¡ç®—å›¾è¡¨ç¤º**

*å‰å‘å›¾*
- èŠ‚ç‚¹ï¼šå˜é‡æˆ–æ“ä½œ
- è¾¹ï¼šæ•°æ®æµå‘
- ä»è¾“å…¥åˆ°è¾“å‡ºçš„æœ‰å‘æ— ç¯å›¾

*åå‘å›¾*
- æ¢¯åº¦çš„åå‘ä¼ æ’­è·¯å¾„
- é“¾å¼æ³•åˆ™çš„å›¾å½¢åŒ–è¡¨ç¤º
- è‡ªåŠ¨å¾®åˆ†çš„åŸºç¡€

**è‡ªåŠ¨å¾®åˆ†**

*å‰å‘æ¨¡å¼*
```
è®¡ç®—f(x)å’Œf'(x)
é€‚åˆè¾“å…¥ç»´åº¦ä½çš„æƒ…å†µ
```

*åå‘æ¨¡å¼*
```
å…ˆè®¡ç®—f(x)ï¼Œå†è®¡ç®—æ¢¯åº¦
é€‚åˆè¾“å‡ºç»´åº¦ä½çš„æƒ…å†µï¼ˆå¦‚ç¥ç»ç½‘ç»œï¼‰
```

*æ··åˆæ¨¡å¼*
- ç»“åˆå‰å‘å’Œåå‘æ¨¡å¼
- ä¼˜åŒ–è®¡ç®—æ•ˆç‡
- ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶çš„å®ç°

#### åå‘ä¼ æ’­ç®—æ³•å®ç°

**ç®—æ³•æ­¥éª¤**

*å‰å‘ä¼ æ’­*
1. è¾“å…¥æ•°æ®x
2. é€å±‚è®¡ç®—ï¼šz^(l) = W^(l)a^(l-1) + b^(l)
3. æ¿€æ´»å‡½æ•°ï¼ša^(l) = Ïƒ(z^(l))
4. è¾“å‡ºé¢„æµ‹ï¼šÅ· = a^(L)
5. è®¡ç®—æŸå¤±ï¼šL = loss(y, Å·)

*åå‘ä¼ æ’­*
1. è¾“å‡ºå±‚è¯¯å·®ï¼šÎ´^(L) = âˆ‡_a L âŠ™ Ïƒ'(z^(L))
2. åå‘ä¼ æ’­è¯¯å·®ï¼šÎ´^(l) = ((W^(l+1))áµ€Î´^(l+1)) âŠ™ Ïƒ'(z^(l))
3. è®¡ç®—æ¢¯åº¦ï¼š
   - âˆ‚L/âˆ‚W^(l) = Î´^(l)(a^(l-1))áµ€
   - âˆ‚L/âˆ‚b^(l) = Î´^(l)
4. æ›´æ–°å‚æ•°ï¼š
   - W^(l) := W^(l) - Î±âˆ‚L/âˆ‚W^(l)
   - b^(l) := b^(l) - Î±âˆ‚L/âˆ‚b^(l)

**æ•°å€¼ç¨³å®šæ€§**

*æ¢¯åº¦æ¶ˆå¤±*
- æ·±å±‚ç½‘ç»œä¸­æ¢¯åº¦é€å±‚è¡°å‡
- æ¿€æ´»å‡½æ•°é¥±å’Œå¯¼è‡´
- è§£å†³æ–¹æ¡ˆï¼šReLUã€æ®‹å·®è¿æ¥ã€æ‰¹å½’ä¸€åŒ–

*æ¢¯åº¦çˆ†ç‚¸*
- æ¢¯åº¦åœ¨åå‘ä¼ æ’­ä¸­æŒ‡æ•°å¢é•¿
- æƒé‡åˆå§‹åŒ–ä¸å½“å¯¼è‡´
- è§£å†³æ–¹æ¡ˆï¼šæ¢¯åº¦è£å‰ªã€æƒé‡åˆå§‹åŒ–ã€å½’ä¸€åŒ–

## ç¬¬äºŒç« ï¼šç°ä»£ç¥ç»ç½‘ç»œæ¶æ„

### 2.1 å·ç§¯ç¥ç»ç½‘ç»œæ·±å…¥

#### å·ç§¯æ“ä½œçš„æ•°å­¦åŸç†

**ç¦»æ•£å·ç§¯**

*ä¸€ç»´å·ç§¯*
```
(f * g)[n] = âˆ‘â‚˜ f[m]g[n-m]
```

*äºŒç»´å·ç§¯*
```
(f * g)[i,j] = âˆ‘â‚˜ âˆ‘â‚™ f[m,n]g[i-m,j-n]
```

*äº’ç›¸å…³ï¼ˆCross-correlationï¼‰*
```
(f â‹† g)[i,j] = âˆ‘â‚˜ âˆ‘â‚™ f[m,n]g[i+m,j+n]
```
- æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸ä½¿ç”¨äº’ç›¸å…³
- ç§°ä¸º"å·ç§¯"æ˜¯å†å²åŸå› 

**å·ç§¯çš„æ€§è´¨**

*å¹³ç§»ç­‰å˜æ€§*
- è¾“å…¥å¹³ç§»ï¼Œè¾“å‡ºç›¸åº”å¹³ç§»
- é€‚åˆå¤„ç†ç©ºé—´æ•°æ®
- å‚æ•°å…±äº«çš„ç†è®ºåŸºç¡€

*å±€éƒ¨è¿æ¥*
- æ¯ä¸ªè¾“å‡ºåªä¾èµ–å±€éƒ¨è¾“å…¥
- å‡å°‘å‚æ•°æ•°é‡
- ç¬¦åˆè§†è§‰æ„Ÿå—é‡æ¦‚å¿µ

#### é«˜çº§å·ç§¯æŠ€æœ¯

**ç©ºæ´å·ç§¯ï¼ˆDilated Convolutionï¼‰**

*å®šä¹‰*
```
(f *_d g)[i,j] = âˆ‘â‚˜ âˆ‘â‚™ f[m,n]g[i+dÂ·m,j+dÂ·n]
```
- dï¼šç©ºæ´ç‡ï¼ˆdilation rateï¼‰
- æ‰©å¤§æ„Ÿå—é‡è€Œä¸å¢åŠ å‚æ•°
- ä¿æŒåˆ†è¾¨ç‡

*åº”ç”¨*
- è¯­ä¹‰åˆ†å‰²
- éŸ³é¢‘å¤„ç†
- æ—¶é—´åºåˆ—åˆ†æ

**åˆ†ç»„å·ç§¯ï¼ˆGroup Convolutionï¼‰**

*åŸç†*
- å°†è¾“å…¥é€šé“åˆ†æˆgç»„
- æ¯ç»„ç‹¬ç«‹è¿›è¡Œå·ç§¯
- å‡å°‘è®¡ç®—é‡å’Œå‚æ•°

*ä¼˜åŠ¿*
- è®¡ç®—æ•ˆç‡æå‡
- æ¨¡å‹å‹ç¼©
- å¢åŠ æ¨¡å‹å¤šæ ·æ€§

**æ·±åº¦å¯åˆ†ç¦»å·ç§¯**

*åˆ†è§£æ–¹å¼*
1. **æ·±åº¦å·ç§¯**ï¼šæ¯ä¸ªè¾“å…¥é€šé“ç‹¬ç«‹å·ç§¯
2. **é€ç‚¹å·ç§¯**ï¼š1Ã—1å·ç§¯æ··åˆé€šé“ä¿¡æ¯

*å‚æ•°å‡å°‘*
```
æ ‡å‡†å·ç§¯ï¼šD_K Ã— D_K Ã— M Ã— N
å¯åˆ†ç¦»å·ç§¯ï¼šD_K Ã— D_K Ã— M + M Ã— N
å‡å°‘æ¯”ä¾‹ï¼š1/N + 1/D_KÂ²
```

#### ç»å…¸CNNæ¶æ„æ¼”è¿›

**AlexNetï¼ˆ2012ï¼‰**

*åˆ›æ–°ç‚¹*
- ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°
- Dropoutæ­£åˆ™åŒ–
- æ•°æ®å¢å¼º
- GPUå¹¶è¡Œè®­ç»ƒ

*ç½‘ç»œç»“æ„*
```
è¾“å…¥: 224Ã—224Ã—3
Conv1: 96ä¸ª11Ã—11Ã—3æ»¤æ³¢å™¨ï¼Œæ­¥é•¿4
MaxPool1: 3Ã—3ï¼Œæ­¥é•¿2
Conv2: 256ä¸ª5Ã—5Ã—96æ»¤æ³¢å™¨
MaxPool2: 3Ã—3ï¼Œæ­¥é•¿2
Conv3: 384ä¸ª3Ã—3Ã—256æ»¤æ³¢å™¨
Conv4: 384ä¸ª3Ã—3Ã—384æ»¤æ³¢å™¨
Conv5: 256ä¸ª3Ã—3Ã—384æ»¤æ³¢å™¨
MaxPool3: 3Ã—3ï¼Œæ­¥é•¿2
FC1: 4096ä¸ªç¥ç»å…ƒ
FC2: 4096ä¸ªç¥ç»å…ƒ
FC3: 1000ä¸ªç¥ç»å…ƒï¼ˆè¾“å‡ºï¼‰
```

**VGGNetï¼ˆ2014ï¼‰**

*è®¾è®¡åŸåˆ™*
- ä½¿ç”¨å°å·ç§¯æ ¸ï¼ˆ3Ã—3ï¼‰
- å¢åŠ ç½‘ç»œæ·±åº¦
- ç»“æ„ç®€æ´ç»Ÿä¸€

*VGG-16ç»“æ„*
```
è¾“å…¥: 224Ã—224Ã—3
Block1: 2Ã—Conv(64,3Ã—3) + MaxPool
Block2: 2Ã—Conv(128,3Ã—3) + MaxPool
Block3: 3Ã—Conv(256,3Ã—3) + MaxPool
Block4: 3Ã—Conv(512,3Ã—3) + MaxPool
Block5: 3Ã—Conv(512,3Ã—3) + MaxPool
FC: 4096 â†’ 4096 â†’ 1000
```

*ä¼˜åŠ¿*
- è¯æ˜äº†æ·±åº¦çš„é‡è¦æ€§
- å°å·ç§¯æ ¸çš„æœ‰æ•ˆæ€§
- ä¸ºåç»­æ¶æ„å¥ å®šåŸºç¡€

**ResNetï¼ˆ2015ï¼‰**

*æ®‹å·®å­¦ä¹ *
```
F(x) = H(x) - x
è¾“å‡º: H(x) = F(x) + x
```
- å­¦ä¹ æ®‹å·®è€Œéç›´æ¥æ˜ å°„
- è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
- ä½¿è¶…æ·±ç½‘ç»œè®­ç»ƒæˆä¸ºå¯èƒ½

*æ®‹å·®å—è®¾è®¡*
```
åŸºæœ¬å—ï¼ˆBasicBlockï¼‰:
x â†’ Conv(3Ã—3) â†’ BN â†’ ReLU â†’ Conv(3Ã—3) â†’ BN â†’ (+x) â†’ ReLU

ç“¶é¢ˆå—ï¼ˆBottleneckï¼‰:
x â†’ Conv(1Ã—1) â†’ BN â†’ ReLU â†’ Conv(3Ã—3) â†’ BN â†’ ReLU â†’ Conv(1Ã—1) â†’ BN â†’ (+x) â†’ ReLU
```

*ç½‘ç»œå˜ä½“*
- ResNet-18/34ï¼šä½¿ç”¨åŸºæœ¬å—
- ResNet-50/101/152ï¼šä½¿ç”¨ç“¶é¢ˆå—
- æ›´æ·±çš„ç½‘ç»œè·å¾—æ›´å¥½æ€§èƒ½

**DenseNetï¼ˆ2017ï¼‰**

*å¯†é›†è¿æ¥*
```
x_l = H_l([x_0, x_1, ..., x_{l-1}])
```
- æ¯å±‚éƒ½ä¸å‰é¢æ‰€æœ‰å±‚è¿æ¥
- ç‰¹å¾é‡ç”¨å’Œæ¢¯åº¦æµåŠ¨
- å‚æ•°æ•ˆç‡é«˜

*å¯†é›†å—ç»“æ„*
```
DenseBlock:
è¾“å…¥ â†’ [BN-ReLU-Conv(1Ã—1)-BN-ReLU-Conv(3Ã—3)] Ã— k â†’ è¾“å‡º
å¢é•¿ç‡: æ¯å±‚å¢åŠ kä¸ªç‰¹å¾å›¾
```

*ä¼˜åŠ¿*
- ç¼“è§£æ¢¯åº¦æ¶ˆå¤±
- åŠ å¼ºç‰¹å¾ä¼ æ’­
- å‡å°‘å‚æ•°æ•°é‡
- éšå¼æ·±åº¦ç›‘ç£

### 2.2 å¾ªç¯ç¥ç»ç½‘ç»œä¸åºåˆ—å»ºæ¨¡

#### RNNåŸºç¡€ç†è®º

**å¾ªç¯ç»“æ„**

*æ ‡å‡†RNN*
```
h_t = tanh(W_hh h_{t-1} + W_xh x_t + b_h)
y_t = W_hy h_t + b_y
```
- h_tï¼šæ—¶åˆ»tçš„éšè—çŠ¶æ€
- x_tï¼šæ—¶åˆ»tçš„è¾“å…¥
- y_tï¼šæ—¶åˆ»tçš„è¾“å‡º

*å‚æ•°å…±äº«*
- æ‰€æœ‰æ—¶é—´æ­¥å…±äº«å‚æ•°
- å¤„ç†å˜é•¿åºåˆ—
- å‚æ•°æ•°é‡ä¸åºåˆ—é•¿åº¦æ— å…³

**æ¢¯åº¦ä¼ æ’­**

*æ—¶é—´åå‘ä¼ æ’­ï¼ˆBPTTï¼‰*
```
âˆ‚L/âˆ‚W_hh = âˆ‘_t âˆ‚L_t/âˆ‚W_hh
âˆ‚L_t/âˆ‚W_hh = âˆ‘_{k=1}^t âˆ‚L_t/âˆ‚h_t âˆ‚h_t/âˆ‚h_k âˆ‚h_k/âˆ‚W_hh
```

*æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸*
```
âˆ‚h_t/âˆ‚h_k = âˆ_{i=k+1}^t âˆ‚h_i/âˆ‚h_{i-1} = âˆ_{i=k+1}^t W_hh diag(tanh'(...))
```
- å½“|Î»_max(W_hh)| < 1æ—¶æ¢¯åº¦æ¶ˆå¤±
- å½“|Î»_max(W_hh)| > 1æ—¶æ¢¯åº¦çˆ†ç‚¸

#### LSTMè¯¦ç»†åˆ†æ

**é—¨æ§æœºåˆ¶**

*é—å¿˜é—¨*
```
f_t = Ïƒ(W_f Â· [h_{t-1}, x_t] + b_f)
```
- å†³å®šä»ç»†èƒçŠ¶æ€ä¸­ä¸¢å¼ƒä»€ä¹ˆä¿¡æ¯
- Ïƒï¼šsigmoidå‡½æ•°ï¼Œè¾“å‡º0-1

*è¾“å…¥é—¨*
```
i_t = Ïƒ(W_i Â· [h_{t-1}, x_t] + b_i)
CÌƒ_t = tanh(W_C Â· [h_{t-1}, x_t] + b_C)
```
- i_tï¼šå†³å®šå­˜å‚¨ä»€ä¹ˆæ–°ä¿¡æ¯
- CÌƒ_tï¼šå€™é€‰å€¼å‘é‡

*ç»†èƒçŠ¶æ€æ›´æ–°*
```
C_t = f_t * C_{t-1} + i_t * CÌƒ_t
```
- é—å¿˜æ—§ä¿¡æ¯ï¼Œæ·»åŠ æ–°ä¿¡æ¯
- çº¿æ€§ç»„åˆï¼Œæ¢¯åº¦æµåŠ¨å¥½

*è¾“å‡ºé—¨*
```
o_t = Ïƒ(W_o Â· [h_{t-1}, x_t] + b_o)
h_t = o_t * tanh(C_t)
```
- å†³å®šè¾“å‡ºç»†èƒçŠ¶æ€çš„å“ªäº›éƒ¨åˆ†

**LSTMå˜ä½“**

*Peephole LSTM*
- é—¨æ§å‡½æ•°å¯ä»¥çœ‹åˆ°ç»†èƒçŠ¶æ€
- æ›´ç²¾ç»†çš„æ§åˆ¶

*Coupled LSTM*
- é—å¿˜é—¨å’Œè¾“å…¥é—¨è€¦åˆ
- f_t + i_t = 1
- å‡å°‘å‚æ•°

#### GRUç®€åŒ–è®¾è®¡

**é—¨æ§å•å…ƒ**

*é‡ç½®é—¨*
```
r_t = Ïƒ(W_r Â· [h_{t-1}, x_t])
```

*æ›´æ–°é—¨*
```
z_t = Ïƒ(W_z Â· [h_{t-1}, x_t])
```

*å€™é€‰éšè—çŠ¶æ€*
```
hÌƒ_t = tanh(W Â· [r_t * h_{t-1}, x_t])
```

*æœ€ç»ˆéšè—çŠ¶æ€*
```
h_t = (1 - z_t) * h_{t-1} + z_t * hÌƒ_t
```

**GRU vs LSTM**

*GRUä¼˜åŠ¿*
- å‚æ•°æ›´å°‘
- è®¡ç®—æ›´å¿«
- æ€§èƒ½ç›¸å½“

*LSTMä¼˜åŠ¿*
- æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
- æ›´å¥½çš„é•¿æœŸè®°å¿†
- æ›´å¤šçš„æ§åˆ¶æœºåˆ¶

#### åŒå‘RNNä¸æ³¨æ„åŠ›æœºåˆ¶

**åŒå‘RNN**

*ç»“æ„*
```
å‰å‘: hâƒ—_t = RNN(x_t, hâƒ—_{t-1})
åå‘: hâƒ–_t = RNN(x_t, hâƒ–_{t+1})
è¾“å‡º: h_t = [hâƒ—_t; hâƒ–_t]
```

*ä¼˜åŠ¿*
- åˆ©ç”¨å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- é€‚åˆåºåˆ—æ ‡æ³¨ä»»åŠ¡
- æé«˜è¡¨ç¤ºè´¨é‡

**æ³¨æ„åŠ›æœºåˆ¶**

*åŸºæœ¬æ€æƒ³*
- åŠ¨æ€é€‰æ‹©ç›¸å…³ä¿¡æ¯
- è§£å†³é•¿åºåˆ—é—®é¢˜
- æä¾›å¯è§£é‡Šæ€§

*è®¡ç®—æ­¥éª¤*
1. **è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°**ï¼še_i = a(s, h_i)
2. **å½’ä¸€åŒ–**ï¼šÎ±_i = exp(e_i) / âˆ‘_j exp(e_j)
3. **åŠ æƒæ±‚å’Œ**ï¼šc = âˆ‘_i Î±_i h_i

*æ³¨æ„åŠ›å‡½æ•°*
- **åŠ æ€§æ³¨æ„åŠ›**ï¼ša(s,h) = v^T tanh(W_s s + W_h h)
- **ä¹˜æ€§æ³¨æ„åŠ›**ï¼ša(s,h) = s^T W h
- **ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›**ï¼ša(s,h) = (s^T h) / âˆšd

### 2.3 Transformeræ¶æ„é©å‘½

#### è‡ªæ³¨æ„åŠ›æœºåˆ¶

**å¤šå¤´è‡ªæ³¨æ„åŠ›**

*æŸ¥è¯¢ã€é”®ã€å€¼*
```
Q = XW^Q
K = XW^K  
V = XW^V
```
- Xï¼šè¾“å…¥åºåˆ—
- W^Q, W^K, W^Vï¼šå­¦ä¹ çš„æŠ•å½±çŸ©é˜µ

*æ³¨æ„åŠ›è®¡ç®—*
```
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
```
- âˆšd_kï¼šç¼©æ”¾å› å­ï¼Œé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±

*å¤šå¤´æœºåˆ¶*
```
head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)
MultiHead(Q,K,V) = Concat(head_1,...,head_h)W^O
```
- hï¼šå¤´æ•°
- å­¦ä¹ ä¸åŒç±»å‹çš„å…³ç³»

**ä½ç½®ç¼–ç **

*æ­£å¼¦ä½ç½®ç¼–ç *
```
PE(pos,2i) = sin(pos/10000^{2i/d_{model}})
PE(pos,2i+1) = cos(pos/10000^{2i/d_{model}})
```
- posï¼šä½ç½®
- iï¼šç»´åº¦
- ç›¸å¯¹ä½ç½®ä¿¡æ¯

*å­¦ä¹ ä½ç½®ç¼–ç *
- å¯å­¦ä¹ çš„ä½ç½®åµŒå…¥
- é€‚åº”ç‰¹å®šä»»åŠ¡
- éœ€è¦å›ºå®šæœ€å¤§é•¿åº¦

#### Transformeræ¶æ„è¯¦è§£

**ç¼–ç å™¨ç»“æ„**

*ç¼–ç å™¨å±‚*
```
è¾“å…¥ â†’ å¤šå¤´è‡ªæ³¨æ„åŠ› â†’ æ®‹å·®è¿æ¥&å±‚å½’ä¸€åŒ– â†’ å‰é¦ˆç½‘ç»œ â†’ æ®‹å·®è¿æ¥&å±‚å½’ä¸€åŒ– â†’ è¾“å‡º
```

*å‰é¦ˆç½‘ç»œ*
```
FFN(x) = max(0, xW_1 + b_1)W_2 + b_2
```
- ä¸¤å±‚çº¿æ€§å˜æ¢
- ReLUæ¿€æ´»å‡½æ•°
- ä½ç½®ç‹¬ç«‹å¤„ç†

**è§£ç å™¨ç»“æ„**

*è§£ç å™¨å±‚*
```
è¾“å…¥ â†’ æ©ç å¤šå¤´è‡ªæ³¨æ„åŠ› â†’ æ®‹å·®è¿æ¥&å±‚å½’ä¸€åŒ– â†’ ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ› â†’ æ®‹å·®è¿æ¥&å±‚å½’ä¸€åŒ– â†’ å‰é¦ˆç½‘ç»œ â†’ æ®‹å·®è¿æ¥&å±‚å½’ä¸€åŒ– â†’ è¾“å‡º
```

*æ©ç æœºåˆ¶*
- é˜²æ­¢çœ‹åˆ°æœªæ¥ä¿¡æ¯
- ä¿è¯è‡ªå›å½’ç‰¹æ€§
- è®­ç»ƒå’Œæ¨ç†ä¸€è‡´æ€§

**å±‚å½’ä¸€åŒ–**

*è®¡ç®—å…¬å¼*
```
LayerNorm(x) = Î³ * (x - Î¼) / Ïƒ + Î²
```
- Î¼, Ïƒï¼šå±‚å†…ç»Ÿè®¡é‡
- Î³, Î²ï¼šå¯å­¦ä¹ å‚æ•°

*ä¼˜åŠ¿*
- ç¨³å®šè®­ç»ƒ
- åŠ é€Ÿæ”¶æ•›
- å‡å°‘å†…éƒ¨åå˜é‡åç§»

#### Transformerå˜ä½“

**BERTï¼ˆåŒå‘ç¼–ç å™¨ï¼‰**

*é¢„è®­ç»ƒä»»åŠ¡*
1. **æ©ç è¯­è¨€æ¨¡å‹ï¼ˆMLMï¼‰**
   - éšæœºæ©ç 15%çš„è¯
   - é¢„æµ‹è¢«æ©ç çš„è¯
   - å­¦ä¹ åŒå‘è¡¨ç¤º

2. **ä¸‹ä¸€å¥é¢„æµ‹ï¼ˆNSPï¼‰**
   - åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦è¿ç»­
   - å­¦ä¹ å¥å­å…³ç³»

*å¾®è°ƒç­–ç•¥*
- åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šæ·»åŠ ä»»åŠ¡å±‚
- ç«¯åˆ°ç«¯å¾®è°ƒ
- é€‚åº”ä¸‹æ¸¸ä»»åŠ¡

**GPTï¼ˆç”Ÿæˆå¼é¢„è®­ç»ƒï¼‰**

*è‡ªå›å½’è¯­è¨€æ¨¡å‹*
```
P(x) = âˆ_{i=1}^n P(x_i | x_1, ..., x_{i-1})
```
- ä»å·¦åˆ°å³ç”Ÿæˆ
- å•å‘æ³¨æ„åŠ›
- ç”Ÿæˆèƒ½åŠ›å¼º

*æ‰©å±•ç­–ç•¥*
- GPT-1: 1.17äº¿å‚æ•°
- GPT-2: 15äº¿å‚æ•°
- GPT-3: 1750äº¿å‚æ•°
- è§„æ¨¡æ•ˆåº”æ˜¾è‘—

**T5ï¼ˆText-to-Text Transfer Transformerï¼‰**

*ç»Ÿä¸€æ¡†æ¶*
- æ‰€æœ‰ä»»åŠ¡è½¬æ¢ä¸ºæ–‡æœ¬ç”Ÿæˆ
- ç¼–ç å™¨-è§£ç å™¨æ¶æ„
- ä»»åŠ¡å‰ç¼€æŒ‡ç¤º

*é¢„è®­ç»ƒç­–ç•¥*
- è·¨åº¦å»å™ª
- å¤šä»»åŠ¡å­¦ä¹ 
- å¤§è§„æ¨¡æ•°æ®

## ç¬¬ä¸‰ç« ï¼šè®­ç»ƒä¼˜åŒ–æŠ€æœ¯

### 3.1 ä¼˜åŒ–ç®—æ³•

#### æ¢¯åº¦ä¸‹é™åŠå…¶å˜ä½“

**æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBGDï¼‰**

*ç®—æ³•*
```
Î¸ := Î¸ - Î±âˆ‡_Î¸ J(Î¸)
```
- ä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®
- æ”¶æ•›ç¨³å®š
- è®¡ç®—å¼€é”€å¤§

**éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰**

*ç®—æ³•*
```
Î¸ := Î¸ - Î±âˆ‡_Î¸ J(Î¸; x^(i), y^(i))
```
- ä½¿ç”¨å•ä¸ªæ ·æœ¬
- æ›´æ–°é¢‘ç¹
- å™ªå£°å¤§ï¼Œå¯èƒ½è·³å‡ºå±€éƒ¨æœ€ä¼˜

**å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch GDï¼‰**

*ç®—æ³•*
```
Î¸ := Î¸ - Î±âˆ‡_Î¸ J(Î¸; x^(i:i+n), y^(i:i+n))
```
- å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œç¨³å®šæ€§
- åˆ©ç”¨å‘é‡åŒ–è®¡ç®—
- ç°ä»£æ·±åº¦å­¦ä¹ çš„æ ‡å‡†

#### è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•

**Momentum**

*ç®—æ³•*
```
v_t = Î²v_{t-1} + Î±âˆ‡_Î¸ J(Î¸)
Î¸ := Î¸ - v_t
```
- ç´¯ç§¯å†å²æ¢¯åº¦
- åŠ é€Ÿæ”¶æ•›
- å‡å°‘éœ‡è¡

*ç‰©ç†è§£é‡Š*
- æ¨¡æ‹Ÿç‰©ç†ä¸­çš„åŠ¨é‡
- æƒ¯æ€§ä½œç”¨
- å†²å‡ºå±€éƒ¨æœ€ä¼˜

**Nesterov Accelerated Gradient**

*ç®—æ³•*
```
v_t = Î²v_{t-1} + Î±âˆ‡_Î¸ J(Î¸ - Î²v_{t-1})
Î¸ := Î¸ - v_t
```
- é¢„æµ‹æœªæ¥ä½ç½®çš„æ¢¯åº¦
- æ›´æ™ºèƒ½çš„ä¿®æ­£
- æ›´å¿«çš„æ”¶æ•›

**AdaGrad**

*ç®—æ³•*
```
G_t = G_{t-1} + (âˆ‡_Î¸ J(Î¸))^2
Î¸ := Î¸ - Î±/(âˆšG_t + Îµ) * âˆ‡_Î¸ J(Î¸)
```
- è‡ªé€‚åº”å­¦ä¹ ç‡
- é¢‘ç¹æ›´æ–°çš„å‚æ•°å­¦ä¹ ç‡è¡°å‡
- é€‚åˆç¨€ç–æ•°æ®

*é—®é¢˜*
- å­¦ä¹ ç‡å•è°ƒé€’å‡
- å¯èƒ½è¿‡æ—©åœæ­¢å­¦ä¹ 

**RMSprop**

*ç®—æ³•*
```
E[g^2]_t = Î²E[g^2]_{t-1} + (1-Î²)(âˆ‡_Î¸ J(Î¸))^2
Î¸ := Î¸ - Î±/(âˆšE[g^2]_t + Îµ) * âˆ‡_Î¸ J(Î¸)
```
- æŒ‡æ•°ç§»åŠ¨å¹³å‡
- è§£å†³AdaGradå­¦ä¹ ç‡è¡°å‡é—®é¢˜
- é€‚åˆéå¹³ç¨³ç›®æ ‡

**Adam**

*ç®—æ³•*
```
m_t = Î²_1 m_{t-1} + (1-Î²_1)âˆ‡_Î¸ J(Î¸)
v_t = Î²_2 v_{t-1} + (1-Î²_2)(âˆ‡_Î¸ J(Î¸))^2
mÌ‚_t = m_t / (1-Î²_1^t)
vÌ‚_t = v_t / (1-Î²_2^t)
Î¸ := Î¸ - Î± * mÌ‚_t / (âˆšvÌ‚_t + Îµ)
```
- ç»“åˆMomentumå’ŒRMSprop
- åå·®ä¿®æ­£
- å¹¿æ³›ä½¿ç”¨çš„ä¼˜åŒ–å™¨

*è¶…å‚æ•°è®¾ç½®*
- Î± = 0.001
- Î²_1 = 0.9
- Î²_2 = 0.999
- Îµ = 1e-8

**AdamW**

*æƒé‡è¡°å‡*
```
Î¸ := Î¸ - Î± * (mÌ‚_t / (âˆšvÌ‚_t + Îµ) + Î»Î¸)
```
- è§£è€¦æƒé‡è¡°å‡å’Œæ¢¯åº¦æ›´æ–°
- æ›´å¥½çš„æ³›åŒ–æ€§èƒ½
- ç°ä»£Transformerçš„æ ‡å‡†

#### å­¦ä¹ ç‡è°ƒåº¦

**å›ºå®šè°ƒåº¦**

*æ­¥é•¿è¡°å‡*
```
Î±_t = Î±_0 * Î³^âŒŠt/sâŒ‹
```
- Î³ï¼šè¡°å‡å› å­
- sï¼šæ­¥é•¿é—´éš”

*æŒ‡æ•°è¡°å‡*
```
Î±_t = Î±_0 * e^{-Î»t}
```

*å¤šé¡¹å¼è¡°å‡*
```
Î±_t = Î±_0 * (1 - t/T)^p
```

**è‡ªé€‚åº”è°ƒåº¦**

*ReduceLROnPlateau*
- ç›‘æ§éªŒè¯æŒ‡æ ‡
- åœæ»æ—¶é™ä½å­¦ä¹ ç‡
- è‡ªåŠ¨è°ƒæ•´

*ä½™å¼¦é€€ç«*
```
Î±_t = Î±_{min} + (Î±_{max} - Î±_{min}) * (1 + cos(Ï€t/T)) / 2
```
- å‘¨æœŸæ€§è°ƒæ•´
- é‡å¯æœºåˆ¶
- è·³å‡ºå±€éƒ¨æœ€ä¼˜

**é¢„çƒ­ç­–ç•¥**

*çº¿æ€§é¢„çƒ­*
```
Î±_t = Î±_{target} * t / t_{warmup}, t â‰¤ t_{warmup}
```
- é¿å…åˆæœŸå¤§å¹…æ›´æ–°
- ç¨³å®šè®­ç»ƒ
- å¤§æ‰¹é‡è®­ç»ƒå¿…éœ€

### 3.2 æ­£åˆ™åŒ–æŠ€æœ¯

#### æƒé‡æ­£åˆ™åŒ–

**L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰**

*ç›®æ ‡å‡½æ•°*
```
L = L_0 + Î»âˆ‘|w_i|
```
- ä¿ƒè¿›ç¨€ç–æ€§
- ç‰¹å¾é€‰æ‹©
- ä¸å¯å¾®åˆ†

**L2æ­£åˆ™åŒ–ï¼ˆRidgeï¼‰**

*ç›®æ ‡å‡½æ•°*
```
L = L_0 + Î»âˆ‘w_i^2
```
- å‚æ•°æ”¶ç¼©
- é˜²æ­¢è¿‡æ‹Ÿåˆ
- å¯å¾®åˆ†

**å¼¹æ€§ç½‘ç»œ**

*ç›®æ ‡å‡½æ•°*
```
L = L_0 + Î»_1âˆ‘|w_i| + Î»_2âˆ‘w_i^2
```
- ç»“åˆL1å’ŒL2
- å¹³è¡¡ç¨€ç–æ€§å’Œæ”¶ç¼©

#### DropoutæŠ€æœ¯

**æ ‡å‡†Dropout**

*è®­ç»ƒæ—¶*
```
r ~ Bernoulli(p)
á»¹ = r âŠ™ y / p
```
- éšæœºç½®é›¶ç¥ç»å…ƒ
- é˜²æ­¢å…±é€‚åº”
- éšå¼é›†æˆ

*æµ‹è¯•æ—¶*
```
á»¹ = y
```
- ä½¿ç”¨æ‰€æœ‰ç¥ç»å…ƒ
- æœŸæœ›ä¿æŒä¸å˜

**Dropoutå˜ä½“**

*DropConnect*
- éšæœºç½®é›¶è¿æ¥æƒé‡
- æ›´ç»†ç²’åº¦çš„æ­£åˆ™åŒ–

*Spatial Dropout*
- æ•´ä¸ªç‰¹å¾å›¾ç½®é›¶
- é€‚åˆå·ç§¯å±‚

*Stochastic Depth*
- éšæœºè·³è¿‡æ•´å±‚
- é€‚åˆæ·±åº¦ç½‘ç»œ

#### æ‰¹å½’ä¸€åŒ–

**ç®—æ³•åŸç†**

*å½’ä¸€åŒ–*
```
Î¼_B = (1/m)âˆ‘x_i
Ïƒ_B^2 = (1/m)âˆ‘(x_i - Î¼_B)^2
xÌ‚_i = (x_i - Î¼_B) / âˆš(Ïƒ_B^2 + Îµ)
```

*ç¼©æ”¾å’Œå¹³ç§»*
```
y_i = Î³xÌ‚_i + Î²
```
- Î³, Î²ï¼šå¯å­¦ä¹ å‚æ•°
- æ¢å¤è¡¨è¾¾èƒ½åŠ›

**ä¼˜åŠ¿**

*å†…éƒ¨åå˜é‡åç§»*
- å‡å°‘å±‚é—´åˆ†å¸ƒå˜åŒ–
- ç¨³å®šè®­ç»ƒè¿‡ç¨‹

*æ¢¯åº¦æµåŠ¨*
- æ”¹å–„æ¢¯åº¦ä¼ æ’­
- å…è®¸æ›´é«˜å­¦ä¹ ç‡
- åŠ é€Ÿæ”¶æ•›

*æ­£åˆ™åŒ–æ•ˆæœ*
- å‡å°‘å¯¹åˆå§‹åŒ–çš„ä¾èµ–
- éšå¼æ­£åˆ™åŒ–
- æé«˜æ³›åŒ–èƒ½åŠ›

**å½’ä¸€åŒ–å˜ä½“**

*Layer Normalization*
```
Î¼ = (1/H)âˆ‘h_i
Ïƒ^2 = (1/H)âˆ‘(h_i - Î¼)^2
```
- åœ¨ç‰¹å¾ç»´åº¦å½’ä¸€åŒ–
- é€‚åˆRNN
- ä¸ä¾èµ–æ‰¹é‡å¤§å°

*Instance Normalization*
- åœ¨æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹å½’ä¸€åŒ–
- é€‚åˆé£æ ¼è¿ç§»

*Group Normalization*
- å°†é€šé“åˆ†ç»„å½’ä¸€åŒ–
- å¹³è¡¡BNå’ŒLN
- é€‚åˆå°æ‰¹é‡

### 3.3 è®­ç»ƒæŠ€å·§ä¸è°ƒè¯•

#### æƒé‡åˆå§‹åŒ–

**Xavier/Glorotåˆå§‹åŒ–**

*å‡åŒ€åˆ†å¸ƒ*
```
W ~ U[-âˆš(6/(n_in + n_out)), âˆš(6/(n_in + n_out))]
```

*æ­£æ€åˆ†å¸ƒ*
```
W ~ N(0, 2/(n_in + n_out))
```
- ä¿æŒå‰å‘ä¼ æ’­æ–¹å·®
- é€‚åˆtanhå’Œsigmoid

**Heåˆå§‹åŒ–**

*æ­£æ€åˆ†å¸ƒ*
```
W ~ N(0, 2/n_in)
```
- è€ƒè™‘ReLUçš„ç‰¹æ€§
- é€‚åˆReLUæ¿€æ´»å‡½æ•°
- ç°ä»£ç½‘ç»œçš„æ ‡å‡†

**LSUVåˆå§‹åŒ–**
- Layer-sequential unit-variance
- é€å±‚åˆå§‹åŒ–
- ä¿è¯å•ä½æ–¹å·®

#### æ¢¯åº¦é—®é¢˜è¯Šæ–­

**æ¢¯åº¦æ¶ˆå¤±**

*ç—‡çŠ¶*
- æµ…å±‚æ¢¯åº¦å¾ˆå°
- è®­ç»ƒç¼“æ…¢æˆ–åœæ»
- æƒé‡æ›´æ–°å¾®å°

*è§£å†³æ–¹æ¡ˆ*
- ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°
- æ®‹å·®è¿æ¥
- æ‰¹å½’ä¸€åŒ–
- æ¢¯åº¦è£å‰ª
- æ›´å¥½çš„åˆå§‹åŒ–

**æ¢¯åº¦çˆ†ç‚¸**

*ç—‡çŠ¶*
- æ¢¯åº¦å€¼å¾ˆå¤§
- æŸå¤±éœ‡è¡æˆ–å‘æ•£
- æƒé‡æ›´æ–°è¿‡å¤§

*è§£å†³æ–¹æ¡ˆ*
```
æ¢¯åº¦è£å‰ª:
if ||g|| > threshold:
    g = g * threshold / ||g||
```

#### è¶…å‚æ•°è°ƒä¼˜

**ç½‘æ ¼æœç´¢**
- ç©·ä¸¾æ‰€æœ‰ç»„åˆ
- é€‚åˆå‚æ•°å°‘çš„æƒ…å†µ
- è®¡ç®—å¼€é”€å¤§

**éšæœºæœç´¢**
- éšæœºé‡‡æ ·å‚æ•°
- æ›´é«˜æ•ˆ
- é€‚åˆé«˜ç»´å‚æ•°ç©ºé—´

**è´å¶æ–¯ä¼˜åŒ–**
- å»ºç«‹ä»£ç†æ¨¡å‹
- å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨
- é€‚åˆæ˜‚è´µçš„è¯„ä¼°

**å¤šä¿çœŸåº¦ä¼˜åŒ–**
- Successive Halving
- Hyperband
- BOHB
- æ—©åœä½æ€§èƒ½é…ç½®

#### è®­ç»ƒç›‘æ§ä¸è°ƒè¯•

**æŸå¤±æ›²çº¿åˆ†æ**

*æ­£å¸¸è®­ç»ƒ*
- è®­ç»ƒæŸå¤±å•è°ƒä¸‹é™
- éªŒè¯æŸå¤±å…ˆé™åå‡
- æ”¶æ•›åˆ°ç¨³å®šå€¼

*è¿‡æ‹Ÿåˆ*
- è®­ç»ƒæŸå¤±æŒç»­ä¸‹é™
- éªŒè¯æŸå¤±ä¸Šå‡
- æ³›åŒ–å·®è·å¢å¤§

*æ¬ æ‹Ÿåˆ*
- è®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½å¾ˆé«˜
- æ”¶æ•›åˆ°æ¬¡ä¼˜è§£
- æ¨¡å‹å®¹é‡ä¸è¶³

**æ¢¯åº¦å’Œæƒé‡ç›‘æ§**

*æ¢¯åº¦ç»Ÿè®¡*
- æ¢¯åº¦èŒƒæ•°
- æ¢¯åº¦åˆ†å¸ƒ
- å±‚é—´æ¢¯åº¦æ¯”ä¾‹

*æƒé‡ç»Ÿè®¡*
- æƒé‡èŒƒæ•°
- æƒé‡æ›´æ–°æ¯”ä¾‹
- æƒé‡åˆ†å¸ƒå˜åŒ–

**æ¿€æ´»å€¼åˆ†æ**

*æ¿€æ´»ç»Ÿè®¡*
- æ¿€æ´»å€¼åˆ†å¸ƒ
- æ­»ç¥ç»å…ƒæ¯”ä¾‹
- æ¿€æ´»é¥±å’Œç¨‹åº¦

*ç‰¹å¾å¯è§†åŒ–*
- t-SNEé™ç»´
- æ¿€æ´»æœ€å¤§åŒ–
- æ¢¯åº¦ä¸Šå‡

## å®è·µé¡¹ç›®

### é¡¹ç›®ä¸€ï¼šä»é›¶å®ç°ç¥ç»ç½‘ç»œæ¡†æ¶

**é¡¹ç›®ç›®æ ‡**
- æ·±å…¥ç†è§£æ·±åº¦å­¦ä¹ åŸç†
- å®ç°è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿ
- æ„å»ºå¯æ‰©å±•çš„æ¡†æ¶

**æ ¸å¿ƒç»„ä»¶**

*å¼ é‡ç±»*
```python
class Tensor:
    def __init__(self, data, requires_grad=False):
        self.data = data
        self.grad = None
        self.requires_grad = requires_grad
        self.grad_fn = None
    
    def backward(self, grad=None):
        # åå‘ä¼ æ’­å®ç°
        pass
```

*è‡ªåŠ¨å¾®åˆ†*
```python
class Function:
    def forward(self, *args):
        raise NotImplementedError
    
    def backward(self, grad_output):
        raise NotImplementedError
```

*ç¥ç»ç½‘ç»œå±‚*
```python
class Linear:
    def __init__(self, in_features, out_features):
        self.weight = Tensor(init_weights(out_features, in_features))
        self.bias = Tensor(init_bias(out_features))
    
    def forward(self, x):
        return x @ self.weight.T + self.bias
```

**å®ç°åŠŸèƒ½**
1. åŸºæœ¬å¼ é‡æ“ä½œ
2. è‡ªåŠ¨å¾®åˆ†æœºåˆ¶
3. å¸¸ç”¨å±‚å®ç°
4. ä¼˜åŒ–å™¨å®ç°
5. æŸå¤±å‡½æ•°
6. è®­ç»ƒå¾ªç¯

### é¡¹ç›®äºŒï¼šå›¾åƒåˆ†ç±»ç³»ç»Ÿ

**é¡¹ç›®ç›®æ ‡**
- å®ç°ç«¯åˆ°ç«¯å›¾åƒåˆ†ç±»
- æ¯”è¾ƒä¸åŒCNNæ¶æ„
- æŒæ¡è®¡ç®—æœºè§†è§‰æŠ€æœ¯

**æ•°æ®é›†**
- CIFAR-10/100
- ImageNetå­é›†
- è‡ªå®šä¹‰æ•°æ®é›†

**æ¨¡å‹å®ç°**

*ResNetå®ç°*
```python
class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out
```

*è®­ç»ƒæµç¨‹*
```python
def train_epoch(model, dataloader, optimizer, criterion):
    model.train()
    total_loss = 0
    correct = 0
    
    for batch_idx, (data, target) in enumerate(dataloader):
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        pred = output.argmax(dim=1)
        correct += pred.eq(target).sum().item()
    
    return total_loss / len(dataloader), correct / len(dataloader.dataset)
```

**æŠ€æœ¯è¦ç‚¹**
- æ•°æ®å¢å¼º
- è¿ç§»å­¦ä¹ 
- æ¨¡å‹é›†æˆ
- æµ‹è¯•æ—¶å¢å¼º

### é¡¹ç›®ä¸‰ï¼šåºåˆ—åˆ°åºåˆ—æ¨¡å‹

**é¡¹ç›®ç›®æ ‡**
- å®ç°æœºå™¨ç¿»è¯‘ç³»ç»Ÿ
- æŒæ¡åºåˆ—å»ºæ¨¡æŠ€æœ¯
- ç†è§£æ³¨æ„åŠ›æœºåˆ¶

**æ¨¡å‹æ¶æ„**

*ç¼–ç å™¨*
```python
class Encoder(nn.Module):
    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)
    
    def forward(self, x):
        embedded = self.embedding(x)
        outputs, (hidden, cell) = self.lstm(embedded)
        return outputs, hidden, cell
```

*æ³¨æ„åŠ›æœºåˆ¶*
```python
class Attention(nn.Module):
    def __init__(self, hidden_size):
        super().__init__()
        self.attn = nn.Linear(hidden_size * 2, hidden_size)
        self.v = nn.Linear(hidden_size, 1, bias=False)
    
    def forward(self, hidden, encoder_outputs):
        seq_len = encoder_outputs.size(1)
        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)
        
        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], dim=2)))
        attention = self.v(energy).squeeze(2)
        
        return F.softmax(attention, dim=1)
```

*è§£ç å™¨*
```python
class Decoder(nn.Module):
    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.attention = Attention(hidden_size)
        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size, num_layers, batch_first=True)
        self.out = nn.Linear(hidden_size, vocab_size)
    
    def forward(self, input, hidden, cell, encoder_outputs):
        input = input.unsqueeze(1)
        embedded = self.embedding(input)
        
        a = self.attention(hidden[-1], encoder_outputs)
        a = a.unsqueeze(1)
        
        weighted = torch.bmm(a, encoder_outputs)
        rnn_input = torch.cat([embedded, weighted], dim=2)
        
        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))
        prediction = self.out(output.squeeze(1))
        
        return prediction, hidden, cell
```

**è®­ç»ƒæŠ€å·§**
- Teacher Forcing
- æŸæœç´¢è§£ç 
- BLEUè¯„ä¼°
- å­¦ä¹ ç‡è°ƒåº¦

### é¡¹ç›®å››ï¼šTransformerå®ç°

**é¡¹ç›®ç›®æ ‡**
- ä»é›¶å®ç°Transformer
- ç†è§£è‡ªæ³¨æ„åŠ›æœºåˆ¶
- æŒæ¡ç°ä»£NLPæŠ€æœ¯

**æ ¸å¿ƒç»„ä»¶**

*å¤šå¤´æ³¨æ„åŠ›*
```python
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_k = d_model // n_heads
        
        self.w_q = nn.Linear(d_model, d_model)
        self.w_k = nn.Linear(d_model, d_model)
        self.w_v = nn.Linear(d_model, d_model)
        self.w_o = nn.Linear(d_model, d_model)
    
    def forward(self, query, key, value, mask=None):
        batch_size = query.size(0)
        
        Q = self.w_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)
        K = self.w_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)
        V = self.w_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)
        
        attn_output = self.attention(Q, K, V, mask)
        attn_output = attn_output.transpose(1, 2).contiguous().view(
            batch_size, -1, self.d_model
        )
        
        return self.w_o(attn_output)
    
    def attention(self, Q, K, V, mask=None):
        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e9)
        
        attn_weights = F.softmax(scores, dim=-1)
        return torch.matmul(attn_weights, V)
```

*ä½ç½®ç¼–ç *
```python
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() *
                           -(math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
    
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]
```

**åº”ç”¨ä»»åŠ¡**
- æœºå™¨ç¿»è¯‘
- æ–‡æœ¬æ‘˜è¦
- é—®ç­”ç³»ç»Ÿ
- è¯­è¨€å»ºæ¨¡

## å­¦ä¹ è¯„ä¼°

### ç†è®ºæŒæ¡è¯„ä¼°

**1. æ•°å­¦åŸºç¡€**
- å¤šå…ƒå¾®ç§¯åˆ†å’Œä¼˜åŒ–ç†è®º
- çº¿æ€§ä»£æ•°å’Œå¼ é‡è¿ç®—
- æ¦‚ç‡è®ºå’Œä¿¡æ¯è®º
- è‡ªåŠ¨å¾®åˆ†åŸç†

**2. ç½‘ç»œæ¶æ„ç†è§£**
- CNNçš„å·ç§¯å’Œæ± åŒ–åŸç†
- RNNçš„å¾ªç¯ç»“æ„å’Œæ¢¯åº¦ä¼ æ’­
- Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶
- å„ç§ç½‘ç»œçš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯

**3. è®­ç»ƒä¼˜åŒ–çŸ¥è¯†**
- å„ç§ä¼˜åŒ–ç®—æ³•çš„åŸç†å’Œç‰¹ç‚¹
- æ­£åˆ™åŒ–æŠ€æœ¯çš„ä½œç”¨æœºåˆ¶
- è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥
- è®­ç»ƒæŠ€å·§å’Œè°ƒè¯•æ–¹æ³•

### å®è·µèƒ½åŠ›è¯„ä¼°

**1. ç¼–ç¨‹å®ç°èƒ½åŠ›**
- ä»é›¶å®ç°åŸºæœ¬ç½‘ç»œç»“æ„
- ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶
- è°ƒè¯•å’Œä¼˜åŒ–ä»£ç 
- å¤„ç†å®é™…æ•°æ®é—®é¢˜

**2. å®éªŒè®¾è®¡èƒ½åŠ›**
- è®¾è®¡åˆç†çš„å¯¹æ¯”å®éªŒ
- é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
- åˆ†æå®éªŒç»“æœ
- å¾—å‡ºæœ‰æ„ä¹‰çš„ç»“è®º

**3. é—®é¢˜è§£å†³èƒ½åŠ›**
- æ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©æ¨¡å‹
- è¯Šæ–­å’Œè§£å†³è®­ç»ƒé—®é¢˜
- ä¼˜åŒ–æ¨¡å‹æ€§èƒ½
- éƒ¨ç½²å’Œåº”ç”¨æ¨¡å‹

### ç»¼åˆåº”ç”¨è¯„ä¼°

**1. é¡¹ç›®å®Œæˆè´¨é‡**
- ä»£ç çš„æ­£ç¡®æ€§å’Œæ•ˆç‡
- å®éªŒçš„å®Œæ•´æ€§å’Œæ·±åº¦
- ç»“æœçš„åˆ†æå’Œè§£é‡Š
- æ–‡æ¡£çš„æ¸…æ™°å’Œå®Œæ•´

**2. åˆ›æ–°æ€ç»´**
- æå‡ºæ”¹è¿›æƒ³æ³•
- å°è¯•æ–°çš„æ–¹æ³•
- è·¨é¢†åŸŸåº”ç”¨
- æ‰¹åˆ¤æ€§æ€è€ƒ

**3. å­¦ä¹ èƒ½åŠ›**
- å¿«é€ŸæŒæ¡æ–°æŠ€æœ¯
- é˜…è¯»å’Œç†è§£è®ºæ–‡
- å¤ç°ç ”ç©¶ç»“æœ
- æŒç»­å­¦ä¹ å’Œæ”¹è¿›

## å»¶ä¼¸å­¦ä¹ 

### å‰æ²¿ç ”ç©¶æ–¹å‘

**æ¶æ„åˆ›æ–°**
- Vision Transformer (ViT)
- Swin Transformer
- ConvNeXt
- MLP-Mixer
- ç¥ç»æ¶æ„æœç´¢ (NAS)

**è®­ç»ƒæ•ˆç‡**
- æ··åˆç²¾åº¦è®­ç»ƒ
- æ¢¯åº¦ç´¯ç§¯
- åˆ†å¸ƒå¼è®­ç»ƒ
- æ¨¡å‹å¹¶è¡Œ
- æ•°æ®å¹¶è¡Œ

**æ¨¡å‹å‹ç¼©**
- çŸ¥è¯†è’¸é¦
- ç½‘ç»œå‰ªæ
- é‡åŒ–æŠ€æœ¯
- ä½ç§©åˆ†è§£
- ç¥ç»ç½‘ç»œå‹ç¼©

**å¯è§£é‡Šæ€§**
- æ³¨æ„åŠ›å¯è§†åŒ–
- æ¢¯åº¦åˆ†æ
- ç‰¹å¾é‡è¦æ€§
- å¯¹æŠ—æ ·æœ¬
- å› æœæ¨ç†

### åº”ç”¨é¢†åŸŸæ‹“å±•

**è®¡ç®—æœºè§†è§‰**
- ç›®æ ‡æ£€æµ‹
- è¯­ä¹‰åˆ†å‰²
- å®ä¾‹åˆ†å‰²
- äººè„¸è¯†åˆ«
- åŒ»å­¦å›¾åƒåˆ†æ

**è‡ªç„¶è¯­è¨€å¤„ç†**
- æœºå™¨ç¿»è¯‘
- æ–‡æœ¬æ‘˜è¦
- æƒ…æ„Ÿåˆ†æ
- é—®ç­”ç³»ç»Ÿ
- å¯¹è¯ç³»ç»Ÿ

**å¤šæ¨¡æ€å­¦ä¹ **
- å›¾åƒæè¿°
- è§†è§‰é—®ç­”
- è§†é¢‘ç†è§£
- è¯­éŸ³è¯†åˆ«
- è·¨æ¨¡æ€æ£€ç´¢

**ç§‘å­¦è®¡ç®—**
- è›‹ç™½è´¨æŠ˜å é¢„æµ‹
- è¯ç‰©å‘ç°
- ææ–™è®¾è®¡
- æ°”å€™å»ºæ¨¡
- ç‰©ç†ä»¿çœŸ

### å·¥ç¨‹å®è·µ

**æ¡†æ¶å’Œå·¥å…·**
- PyTorchæ·±å…¥
- TensorFlow/JAX
- Hugging Face
- MLflow
- Weights & Biases

**éƒ¨ç½²å’Œä¼˜åŒ–**
- ONNXæ¨¡å‹è½¬æ¢
- TensorRTä¼˜åŒ–
- ç§»åŠ¨ç«¯éƒ¨ç½²
- äº‘ç«¯æœåŠ¡
- è¾¹ç¼˜è®¡ç®—

**MLOpså®è·µ**
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- å®éªŒè·Ÿè¸ª
- è‡ªåŠ¨åŒ–è®­ç»ƒ
- æ¨¡å‹ç›‘æ§
- A/Bæµ‹è¯•

## æ€»ç»“

æœ¬æ¨¡å—æ·±å…¥æ¢è®¨äº†æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œä»æ•°å­¦åŸºç¡€åˆ°ç°ä»£æ¶æ„ï¼Œä»è®­ç»ƒä¼˜åŒ–åˆ°å®è·µåº”ç”¨ã€‚é€šè¿‡ç³»ç»Ÿçš„å­¦ä¹ ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

**æ ¸å¿ƒæ”¶è·**ï¼š
1. **ç†è®ºåŸºç¡€**ï¼šæŒæ¡æ·±åº¦å­¦ä¹ çš„æ•°å­¦åŸç†å’Œç†è®ºåŸºç¡€
2. **æ¶æ„ç†è§£**ï¼šæ·±å…¥ç†è§£CNNã€RNNã€Transformerç­‰æ ¸å¿ƒæ¶æ„
3. **è®­ç»ƒæŠ€èƒ½**ï¼šæŒæ¡ä¼˜åŒ–ç®—æ³•ã€æ­£åˆ™åŒ–æŠ€æœ¯å’Œè®­ç»ƒæŠ€å·§
4. **å®è·µèƒ½åŠ›**ï¼šèƒ½å¤Ÿå®ç°ã€è®­ç»ƒå’Œä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹

**å…³é”®æŠ€èƒ½**ï¼š
- ç½‘ç»œæ¶æ„è®¾è®¡å’Œé€‰æ‹©
- è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–å’Œè°ƒè¯•
- æ¨¡å‹æ€§èƒ½è¯„ä¼°å’Œæ”¹è¿›
- å®é™…é—®é¢˜çš„å»ºæ¨¡å’Œè§£å†³

**æœªæ¥æ–¹å‘**ï¼š
- å…³æ³¨æœ€æ–°çš„æ¶æ„åˆ›æ–°
- æ¢ç´¢ç‰¹å®šé¢†åŸŸçš„åº”ç”¨
- å­¦ä¹ æ¨¡å‹å‹ç¼©å’Œéƒ¨ç½²
- å‚ä¸å¼€æºé¡¹ç›®å’Œç ”ç©¶

æ·±åº¦å­¦ä¹ æ˜¯ä¸€ä¸ªå¿«é€Ÿå‘å±•çš„é¢†åŸŸï¼ŒæŒæ¡è¿™äº›æ ¸å¿ƒæŠ€æœ¯ä¸ºä½ åœ¨AIé¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•å¥ å®šäº†åšå®åŸºç¡€ã€‚ç»§ç»­ä¿æŒå­¦ä¹ å’Œå®è·µï¼Œè·Ÿä¸ŠæŠ€æœ¯å‘å±•çš„æ­¥ä¼ã€‚